---
# generated by https://github.com/hashicorp/terraform-plugin-docs
page_title: "seqera_aws_batch_ce Resource - terraform-provider-seqera"
subcategory: ""
description: |-
  Manage AWS compute environments in Seqera platform using this resource.
  AWS compute environments define the execution platform where a pipeline will run
  on AWS infrastructure (AWS Batch, AWS Cloud, EKS).
---

# seqera_aws_batch_ce (Resource)

Manage AWS compute environments in Seqera platform using this resource.

AWS compute environments define the execution platform where a pipeline will run
on AWS infrastructure (AWS Batch, AWS Cloud, EKS).

## Example Usage

```terraform
resource "seqera_aws_batch_ce" "my_awsbatchce" {
  config = {
    cli_path             = "/home/ec2-user/miniconda/bin/aws"
    compute_job_role     = "arn:aws:iam::123456789012:role/BatchJobRole"
    compute_queue        = "...my_compute_queue..."
    dragen_instance_type = "...my_dragen_instance_type..."
    dragen_queue         = "...my_dragen_queue..."
    enable_fusion        = true
    enable_wave          = true
    environment = [
      {
        compute = true
        head    = false
        name    = "...my_name..."
        value   = "...my_value..."
      }
    ]
    execution_role = "arn:aws:iam::123456789012:role/BatchExecutionRole"
    forge = {
      alloc_strategy = "SPOT_CAPACITY_OPTIMIZED"
      allow_buckets = [
        "..."
      ]
      arm64_enabled        = true
      bid_percentage       = 20
      dispose_on_deletion  = true
      dragen_ami_id        = "...my_dragen_ami_id..."
      dragen_enabled       = true
      dragen_instance_type = "...my_dragen_instance_type..."
      ebs_auto_scale       = true
      ebs_block_size       = 100
      ebs_boot_size        = 8
      ec2_key_pair         = "my-keypair"
      ecs_config           = "...my_ecs_config..."
      efs_create           = false
      efs_id               = "fs-1234567890abcdef0"
      efs_mount            = "/mnt/efs"
      fargate_head_enabled = false
      fsx_mount            = "/fsx"
      fsx_name             = "my-fsx-filesystem"
      fsx_size             = 1200
      gpu_enabled          = false
      image_id             = "...my_image_id..."
      instance_types = [
        "m5.xlarge",
        "m5.2xlarge",
        "m5.xlarge",
        "m5.2xlarge",
      ]
      max_cpus = 256
      min_cpus = 0
      security_groups = [
        "sg-12345678",
        "sg-12345678",
      ]
      subnets = [
        "subnet-12345",
        "subnet-67890",
        "subnet-12345",
        "subnet-67890",
      ]
      type   = "SPOT"
      vpc_id = "vpc-1234567890abcdef0"
    }
    fusion_snapshots     = false
    head_job_cpus        = 4
    head_job_memory_mb   = 8192
    head_job_role        = "arn:aws:iam::123456789012:role/BatchHeadJobRole"
    head_queue           = "...my_head_queue..."
    log_group            = "...my_log_group..."
    lustre_id            = "...my_lustre_id..."
    nextflow_config      = "...my_nextflow_config..."
    nvme_storage_enabled = true
    post_run_script      = "...my_post_run_script..."
    pre_run_script       = "...my_pre_run_script..."
    region               = "us-east-1"
    storage_type         = "...my_storage_type..."
    volumes = [
      "..."
    ]
    work_dir = "s3://my-nextflow-bucket/work"
  }
  credentials_id = "...my_credentials_id..."
  description    = "...my_description..."
  label_ids = [
    3
  ]
  name         = "...my_name..."
  platform     = "aws-batch"
  workspace_id = 5
}
```

<!-- schema generated by tfplugindocs -->
## Schema

### Required

- `config` (Attributes) Requires replacement if changed. (see [below for nested schema](#nestedatt--config))
- `credentials_id` (String) AWS credentials identifier. Requires replacement if changed.
- `name` (String) Display name for the compute environment. Requires replacement if changed.
- `platform` (String) AWS platform type. must be "aws-batch"; Requires replacement if changed.
- `workspace_id` (Number) Workspace numeric identifier. Requires replacement if changed.

### Optional

- `description` (String) Optional description of the compute environment. Requires replacement if changed.
- `label_ids` (List of Number) Requires replacement if changed.

### Read-Only

- `compute_env_id` (String) Compute environment string identifier
- `date_created` (String) Timestamp when the compute environment was created
- `deleted` (Boolean) Flag indicating if the compute environment has been deleted
- `id` (String) Unique identifier for the compute environment
- `last_updated` (String) Timestamp when the compute environment was last updated
- `last_used` (String) Timestamp when the compute environment was last used
- `org_id` (Number)
- `status` (String) Compute environment status

<a id="nestedatt--config"></a>
### Nested Schema for `config`

Required:

- `region` (String) AWS region where the Batch compute environment will be created.
Examples: us-east-1, eu-west-1, ap-southeast-2
Requires replacement if changed.
- `work_dir` (String) S3 bucket path for Nextflow work directory where intermediate files will be stored.
Format: s3://bucket-name/path
Requires replacement if changed.

Optional:

- `cli_path` (String) Path to AWS CLI on compute instances. AWS CLI must be available at this path. Requires replacement if changed.
- `compute_job_role` (String) IAM role ARN for compute jobs. Jobs assume this role during execution.
Must have permissions for S3, CloudWatch, etc.
Format: arn:aws:iam::account-id:role/role-name
Requires replacement if changed.
- `compute_queue` (String) Name of the AWS Batch compute queue. Requires replacement if changed.
- `dragen_instance_type` (String) Requires replacement if changed.
- `dragen_queue` (String) Requires replacement if changed.
- `enable_fusion` (Boolean) Requires replacement if changed.
- `enable_wave` (Boolean) Enable Wave containers for this compute environment. Wave provides container provisioning
and augmentation capabilities for Nextflow workflows.

When enable_wave is true, enable_fusion must be explicitly set to either true or false.
Note: If Fusion2 is enabled, Wave must also be enabled.
Requires replacement if changed.
- `environment` (Attributes List) Requires replacement if changed. (see [below for nested schema](#nestedatt--config--environment))
- `execution_role` (String) IAM role ARN for Batch execution (pulling container images, writing logs).
Must have permissions for ECR and CloudWatch Logs.
Format: arn:aws:iam::account-id:role/role-name
Requires replacement if changed.
- `forge` (Attributes) Requires replacement if changed. (see [below for nested schema](#nestedatt--config--forge))
- `fusion_snapshots` (Boolean) Requires replacement if changed.
- `head_job_cpus` (Number) Number of CPUs allocated for the head job (default: 1). Requires replacement if changed.
- `head_job_memory_mb` (Number) Memory allocation for the head job in MB (default: 1024). Requires replacement if changed.
- `head_job_role` (String) IAM role ARN for the head job.
Format: arn:aws:iam::account-id:role/role-name
Requires replacement if changed.
- `head_queue` (String) Name of the head job queue. Requires replacement if changed.
- `log_group` (String) Requires replacement if changed.
- `lustre_id` (String, Deprecated) Requires replacement if changed.
- `nextflow_config` (String) Requires replacement if changed.
- `nvme_storage_enabled` (Boolean) Enable NVMe instance storage for high-performance I/O.
When enabled, NVMe storage volumes are automatically mounted and configured.
Requires replacement if changed.
- `post_run_script` (String) Bash script to run after workflow execution completes.
Use for cleanup, archiving results, sending notifications, etc.
Requires replacement if changed.
- `pre_run_script` (String) Bash script to run before workflow execution begins.
Use for environment setup, loading modules, downloading reference data, etc.
Requires replacement if changed.
- `storage_type` (String, Deprecated) Requires replacement if changed.
- `volumes` (List of String) Requires replacement if changed.

<a id="nestedatt--config--environment"></a>
### Nested Schema for `config.environment`

Optional:

- `compute` (Boolean) Whether this environment variable should be applied to compute/worker nodes.
At least one of 'head' or 'compute' must be set to true. Both can be true to target both environments.
Requires replacement if changed.
Default: false; Requires replacement if changed.
- `head` (Boolean) Whether this environment variable should be applied to the head/master node.
At least one of 'head' or 'compute' must be set to true. Both can be true to target both environments.
Requires replacement if changed.
Default: false; Requires replacement if changed.
- `name` (String) Requires replacement if changed.
- `value` (String) Requires replacement if changed.


<a id="nestedatt--config--forge"></a>
### Nested Schema for `config.forge`

Optional:

- `alloc_strategy` (String) Strategy for allocating compute resources:
- BEST_FIT: Selects instance type that best fits job requirements
- BEST_FIT_PROGRESSIVE: Similar to BEST_FIT but widens search progressively
- SPOT_CAPACITY_OPTIMIZED: For Spot instances, selects from pools with optimal capacity
- SPOT_PRICE_CAPACITY_OPTIMIZED: Optimizes for both price and capacity
Note: SPOT_CAPACITY_OPTIMIZED only valid when type is SPOT
must be one of ["BEST_FIT", "BEST_FIT_PROGRESSIVE", "SPOT_CAPACITY_OPTIMIZED", "SPOT_PRICE_CAPACITY_OPTIMIZED"]; Requires replacement if changed.
- `allow_buckets` (List of String) Requires replacement if changed.
- `arm64_enabled` (Boolean) Requires replacement if changed.
- `bid_percentage` (Number) The maximum percentage that a Spot Instance price can be when compared with the On-Demand price
for that instance type before instances are launched. For example, if your maximum percentage is 20%,
then the Spot price must be less than 20% of the current On-Demand price for that Amazon EC2 instance.
You always pay the lowest (market) price and never more than your maximum percentage. If you leave this
field empty, the default value is 100% of the On-Demand price. For most use cases, we recommend leaving
this field empty.

Must be a whole number between 0 and 100 (inclusive).
Requires replacement if changed.
- `dispose_on_deletion` (Boolean) When set to true for AWS Batch forge environments, automatically deletes AWS resources
created during compute environment setup when the Terraform resource is destroyed.

The following AWS resources will be deleted:
1. AWS Batch Compute Environments - The Batch compute environment itself
2. AWS Batch Job Queues - Associated job queues (head queue, compute queue, dragen queue)
3. EC2 Launch Templates - Launch templates for the compute instances
4. IAM Roles - Execution roles, head job roles, and other service roles
5. IAM Instance Profiles - Instance profiles attached to compute instances
6. FSx File Systems - FSx for Lustre file systems (if created during forge)
7. EFS File Systems - Elastic File Systems (if created during forge)

Note: The AWS credentials associated with this compute environment must have appropriate
permissions to delete these resources.

Important: Deleting a workspace with active compute environments will bypass this cleanup
and require manual removal of AWS resources. We recommend deleting compute environments
before deleting workspaces.
Requires replacement if changed.
- `dragen_ami_id` (String) Requires replacement if changed.
- `dragen_enabled` (Boolean) Requires replacement if changed.
- `dragen_instance_type` (String) Requires replacement if changed.
- `ebs_auto_scale` (Boolean) Enable automatic EBS volume expansion.
When enabled, EBS volumes automatically expand as needed.
Requires replacement if changed.
- `ebs_block_size` (Number) Size of EBS root volume in GB (minimum 8 GB, maximum 16 TB). Requires replacement if changed.
- `ebs_boot_size` (Number) Requires replacement if changed.
- `ec2_key_pair` (String) EC2 key pair name for SSH access to compute instances.
Key pair must exist in the specified region.
Requires replacement if changed.
- `ecs_config` (String) Requires replacement if changed.
- `efs_create` (Boolean) Automatically create an EFS file system. Requires replacement if changed.
- `efs_id` (String) EFS file system ID to mount.
Format: fs- followed by hexadecimal characters.
EFS must be in the same VPC and region.
Requires replacement if changed.
- `efs_mount` (String) Path where EFS will be mounted in the container. Requires replacement if changed.
- `fargate_head_enabled` (Boolean) Use Fargate for head job instead of EC2.
Reduces costs by running head job on serverless compute.
Only applicable when using EC2 for worker jobs.
Requires replacement if changed.
- `fsx_mount` (String) Path where FSx will be mounted in the container. Requires replacement if changed.
- `fsx_name` (String) FSx for Lustre file system name. Requires replacement if changed.
- `fsx_size` (Number) Size of FSx file system in GB. Requires replacement if changed.
- `gpu_enabled` (Boolean) Enable GPU support for compute instances.
When enabled, GPU-capable instance types will be selected.
Requires replacement if changed.
- `image_id` (String) Requires replacement if changed.
- `instance_types` (List of String) List of EC2 instance types to use.
Examples: ["m5.xlarge", "m5.2xlarge"], ["c5.2xlarge"], ["p3.2xlarge"]
Default: ["optimal"] - AWS Batch selects appropriate instances
Requires replacement if changed.
- `max_cpus` (Number) Maximum number of CPUs available in the compute environment.
Subject to AWS service quotas.
Not Null; Requires replacement if changed.
- `min_cpus` (Number) Minimum number of CPUs to maintain in the compute environment.
Setting to 0 allows environment to scale to zero when idle.
Requires replacement if changed.
- `security_groups` (List of String) List of security group IDs to attach to compute instances.
Security groups must allow necessary network access.
Requires replacement if changed.
- `subnets` (List of String) List of subnet IDs for compute instances.
Subnets must be in the specified VPC. Use multiple subnets for high availability.
Must have sufficient IP addresses.
Requires replacement if changed.
- `type` (String) Type of compute instances to provision:
- SPOT: Use EC2 Spot instances (cost-effective, can be interrupted)
- EC2: Use On-Demand EC2 instances (reliable, higher cost)
- FARGATE: Use AWS Fargate serverless compute
Not Null; must be one of ["SPOT", "EC2"]; Requires replacement if changed.
- `vpc_id` (String) VPC ID where compute environment will be deployed.
Format: vpc- followed by hexadecimal characters
Requires replacement if changed.

## Import

Import is supported using the following syntax:

In Terraform v1.5.0 and later, the [`import` block](https://developer.hashicorp.com/terraform/language/import) can be used with the `id` attribute, for example:

```terraform
import {
  to = seqera_aws_batch_ce.my_seqera_aws_batch_ce
  id = jsonencode({
    compute_env_id = "..."
    workspace_id = 0
  })
}
```

The [`terraform import` command](https://developer.hashicorp.com/terraform/cli/commands/import) can be used, for example:

```shell
terraform import seqera_aws_batch_ce.my_seqera_aws_batch_ce '{"compute_env_id": "...", "workspace_id": 0}'
```
