// Code generated by Speakeasy (https://speakeasy.com). DO NOT EDIT.

package provider

import (
	"bytes"
	"context"
	"encoding/json"
	"fmt"
	"github.com/hashicorp/terraform-plugin-framework-validators/int32validator"
	"github.com/hashicorp/terraform-plugin-framework-validators/stringvalidator"
	"github.com/hashicorp/terraform-plugin-framework/path"
	"github.com/hashicorp/terraform-plugin-framework/resource"
	"github.com/hashicorp/terraform-plugin-framework/resource/schema"
	"github.com/hashicorp/terraform-plugin-framework/resource/schema/booldefault"
	"github.com/hashicorp/terraform-plugin-framework/resource/schema/int32default"
	"github.com/hashicorp/terraform-plugin-framework/resource/schema/listplanmodifier"
	"github.com/hashicorp/terraform-plugin-framework/resource/schema/planmodifier"
	"github.com/hashicorp/terraform-plugin-framework/resource/schema/stringdefault"
	"github.com/hashicorp/terraform-plugin-framework/resource/schema/stringplanmodifier"
	"github.com/hashicorp/terraform-plugin-framework/schema/validator"
	"github.com/hashicorp/terraform-plugin-framework/types"
	"github.com/hashicorp/terraform-plugin-framework/types/basetypes"
	speakeasy_listplanmodifier "github.com/seqeralabs/terraform-provider-seqera/internal/planmodifiers/listplanmodifier"
	speakeasy_stringplanmodifier "github.com/seqeralabs/terraform-provider-seqera/internal/planmodifiers/stringplanmodifier"
	tfTypes "github.com/seqeralabs/terraform-provider-seqera/internal/provider/types"
	"github.com/seqeralabs/terraform-provider-seqera/internal/sdk"
	custom_boolvalidators "github.com/seqeralabs/terraform-provider-seqera/internal/validators/boolvalidators"
	"regexp"
)

// Ensure provider defined types fully satisfy framework interfaces.
var _ resource.Resource = &AWSBatchComputeEnvResource{}
var _ resource.ResourceWithImportState = &AWSBatchComputeEnvResource{}

func NewAWSBatchComputeEnvResource() resource.Resource {
	return &AWSBatchComputeEnvResource{}
}

// AWSBatchComputeEnvResource defines the resource implementation.
type AWSBatchComputeEnvResource struct {
	// Provider configured SDK client.
	client *sdk.Seqera
}

// AWSBatchComputeEnvResourceModel describes the resource data model.
type AWSBatchComputeEnvResourceModel struct {
	ComputeEnvID  types.String    `tfsdk:"compute_env_id"`
	Config        *tfTypes.Config `tfsdk:"config"`
	CredentialsID types.String    `tfsdk:"credentials_id"`
	Description   types.String    `tfsdk:"description"`
	LabelIds      []types.Int64   `tfsdk:"label_ids"`
	Message       types.String    `tfsdk:"message"`
	Name          types.String    `tfsdk:"name"`
	Region        types.String    `tfsdk:"region"`
	Status        types.String    `tfsdk:"status"`
	WorkDirectory types.String    `tfsdk:"work_directory"`
	WorkspaceID   types.Int64     `queryParam:"style=form,explode=true,name=workspaceId" tfsdk:"workspace_id"`
}

func (r *AWSBatchComputeEnvResource) Metadata(ctx context.Context, req resource.MetadataRequest, resp *resource.MetadataResponse) {
	resp.TypeName = req.ProviderTypeName + "_aws_batch_compute_env"
}

func (r *AWSBatchComputeEnvResource) Schema(ctx context.Context, req resource.SchemaRequest, resp *resource.SchemaResponse) {
	resp.Schema = schema.Schema{
		MarkdownDescription: "Manage AWS Batch compute environments in Seqera Platform.\n\nAWS Batch compute environments provide scalable compute capacity for running\nNextflow workflows on AWS using the AWS Batch service.\n",
		Attributes: map[string]schema.Attribute{
			"compute_env_id": schema.StringAttribute{
				Computed:    true,
				Description: `Unique identifier for the compute environment`,
			},
			"config": schema.SingleNestedAttribute{
				Computed: true,
				Optional: true,
				Attributes: map[string]schema.Attribute{
					"cli_path": schema.StringAttribute{
						Computed:    true,
						Optional:    true,
						Default:     stringdefault.StaticString(`/home/ec2-user/miniconda/bin/aws`),
						Description: `Path to AWS CLI on compute instances. Default: "/home/ec2-user/miniconda/bin/aws"`,
					},
					"compute_job_role": schema.StringAttribute{
						Computed: true,
						Optional: true,
						MarkdownDescription: `IAM role ARN for compute jobs. Jobs assume this role during execution.` + "\n" +
							`Format: arn:aws:iam::account-id:role/role-name`,
						Validators: []validator.String{
							stringvalidator.RegexMatches(regexp.MustCompile(`^arn:aws:iam::[0-9]{12}:role/.+$`), "must match pattern "+regexp.MustCompile(`^arn:aws:iam::[0-9]{12}:role/.+$`).String()),
						},
					},
					"compute_queue": schema.StringAttribute{
						Computed:    true,
						Optional:    true,
						Description: `Name of the AWS Batch compute queue`,
					},
					"enable_fusion": schema.BoolAttribute{
						Computed: true,
						Optional: true,
						Default:  booldefault.StaticBool(false),
						MarkdownDescription: `Enable Fusion v2 for virtual file system. Fusion provides virtual file system` + "\n" +
							`for efficient S3 access and improves performance by lazy loading files.` + "\n" +
							`Default: false`,
					},
					"enable_wave": schema.BoolAttribute{
						Computed: true,
						Optional: true,
						Default:  booldefault.StaticBool(false),
						MarkdownDescription: `Enable Wave containers service. Wave builds and manages container images on-demand.` + "\n" +
							`When enable_wave is true, enable_fusion must be explicitly set.` + "\n" +
							`Default: false`,
						Validators: []validator.Bool{
							custom_boolvalidators.WaveEnabledValidator(),
						},
					},
					"execution_role": schema.StringAttribute{
						Computed: true,
						Optional: true,
						MarkdownDescription: `IAM role ARN for Batch execution (pulling container images, writing logs).` + "\n" +
							`Format: arn:aws:iam::account-id:role/role-name`,
						Validators: []validator.String{
							stringvalidator.RegexMatches(regexp.MustCompile(`^arn:aws:iam::[0-9]{12}:role/.+$`), "must match pattern "+regexp.MustCompile(`^arn:aws:iam::[0-9]{12}:role/.+$`).String()),
						},
					},
					"forge": schema.SingleNestedAttribute{
						Computed: true,
						Optional: true,
						Attributes: map[string]schema.Attribute{
							"allocation_strategy": schema.StringAttribute{
								Computed: true,
								Optional: true,
								MarkdownDescription: `Strategy for allocating compute resources.` + "\n" +
									`SPOT_CAPACITY_OPTIMIZED only valid when forge_type is SPOT.` + "\n" +
									`must be one of ["BEST_FIT", "BEST_FIT_PROGRESSIVE", "SPOT_CAPACITY_OPTIMIZED", "SPOT_PRICE_CAPACITY_OPTIMIZED"]`,
								Validators: []validator.String{
									stringvalidator.OneOf(
										"BEST_FIT",
										"BEST_FIT_PROGRESSIVE",
										"SPOT_CAPACITY_OPTIMIZED",
										"SPOT_PRICE_CAPACITY_OPTIMIZED",
									),
								},
							},
							"bid_percentage": schema.Int32Attribute{
								Computed: true,
								Optional: true,
								MarkdownDescription: `Maximum percentage of On-Demand price to pay for Spot instances (0-100).` + "\n" +
									`Only applicable when forge_type is SPOT.`,
								Validators: []validator.Int32{
									int32validator.AtMost(100),
								},
							},
							"dispose_on_deletion": schema.BoolAttribute{
								Computed:    true,
								Optional:    true,
								Default:     booldefault.StaticBool(true),
								Description: `Dispose of AWS Batch resources when compute environment is deleted. Default: true`,
							},
							"ebs_auto_scale": schema.BoolAttribute{
								Computed:    true,
								Optional:    true,
								Default:     booldefault.StaticBool(false),
								Description: `Enable automatic EBS volume expansion. Default: false`,
							},
							"ebs_block_size": schema.Int32Attribute{
								Computed:    true,
								Optional:    true,
								Default:     int32default.StaticInt32(50),
								Description: `Size of EBS root volume in GB (minimum 8 GB, maximum 16 TB). Default: 50`,
								Validators: []validator.Int32{
									int32validator.Between(8, 16384),
								},
							},
							"ec2_key_pair": schema.StringAttribute{
								Computed:    true,
								Optional:    true,
								Description: `EC2 key pair name for SSH access to compute instances`,
							},
							"efs_create": schema.BoolAttribute{
								Computed:    true,
								Optional:    true,
								Default:     booldefault.StaticBool(false),
								Description: `Automatically create an EFS file system. Default: false`,
							},
							"efs_id": schema.StringAttribute{
								Computed: true,
								Optional: true,
								MarkdownDescription: `EFS file system ID to mount.` + "\n" +
									`Format: fs- followed by hexadecimal characters`,
								Validators: []validator.String{
									stringvalidator.RegexMatches(regexp.MustCompile(`^fs-[a-f0-9]+$`), "must match pattern "+regexp.MustCompile(`^fs-[a-f0-9]+$`).String()),
								},
							},
							"efs_mount": schema.StringAttribute{
								Computed:    true,
								Optional:    true,
								Default:     stringdefault.StaticString(`/mnt/efs`),
								Description: `Path where EFS will be mounted in the container. Default: "/mnt/efs"`,
							},
							"fargate_head_enabled": schema.BoolAttribute{
								Computed: true,
								Optional: true,
								Default:  booldefault.StaticBool(false),
								MarkdownDescription: `Use Fargate for head job instead of EC2.` + "\n" +
									`Reduces costs by running head job on serverless compute.` + "\n" +
									`Default: false`,
							},
							"forge_type": schema.StringAttribute{
								Computed: true,
								Optional: true,
								Default:  stringdefault.StaticString(`EC2`),
								MarkdownDescription: `Type of compute instances to provision:` + "\n" +
									`- SPOT: Use EC2 Spot instances (cost-effective, can be interrupted)` + "\n" +
									`- EC2: Use On-Demand EC2 instances (reliable, higher cost)` + "\n" +
									`- FARGATE: Use AWS Fargate serverless compute` + "\n" +
									`Default: "EC2"; must be one of ["SPOT", "EC2", "FARGATE"]`,
								Validators: []validator.String{
									stringvalidator.OneOf(
										"SPOT",
										"EC2",
										"FARGATE",
									),
								},
							},
							"fsx_mount": schema.StringAttribute{
								Computed:    true,
								Optional:    true,
								Default:     stringdefault.StaticString(`/fsx`),
								Description: `Path where FSx will be mounted in the container. Default: "/fsx"`,
							},
							"fsx_name": schema.StringAttribute{
								Computed:    true,
								Optional:    true,
								Description: `FSx for Lustre file system name`,
							},
							"fsx_size": schema.Int32Attribute{
								Computed:    true,
								Optional:    true,
								Description: `Size of FSx file system in GB`,
							},
							"gpu_enabled": schema.BoolAttribute{
								Computed: true,
								Optional: true,
								Default:  booldefault.StaticBool(false),
								MarkdownDescription: `Enable GPU support for compute instances.` + "\n" +
									`When enabled, GPU-capable instance types will be selected.` + "\n" +
									`Default: false`,
							},
							"instance_types": schema.ListAttribute{
								Computed:    true,
								Optional:    true,
								ElementType: types.StringType,
								MarkdownDescription: `List of EC2 instance types to use.` + "\n" +
									`Examples: ["m5.xlarge", "m5.2xlarge"], ["c5.2xlarge"], ["p3.2xlarge"]` + "\n" +
									`Default: ["optimal"] - AWS Batch selects appropriate instances`,
							},
							"max_cpus": schema.Int32Attribute{
								Computed: true,
								Optional: true,
								Default:  int32default.StaticInt32(256),
								MarkdownDescription: `Maximum number of CPUs available in the compute environment.` + "\n" +
									`Subject to AWS service quotas.` + "\n" +
									`Default: 256`,
								Validators: []validator.Int32{
									int32validator.AtLeast(1),
								},
							},
							"min_cpus": schema.Int32Attribute{
								Computed: true,
								Optional: true,
								Default:  int32default.StaticInt32(0),
								MarkdownDescription: `Minimum number of CPUs to maintain in the compute environment.` + "\n" +
									`Setting to 0 allows environment to scale to zero when idle.` + "\n" +
									`Default: 0`,
							},
							"security_groups": schema.ListAttribute{
								Computed:    true,
								Optional:    true,
								ElementType: types.StringType,
								Description: `List of security group IDs to attach to compute instances`,
							},
							"subnets": schema.ListAttribute{
								Computed: true,
								Optional: true,
								PlanModifiers: []planmodifier.List{
									listplanmodifier.RequiresReplaceIfConfigured(),
									speakeasy_listplanmodifier.SuppressDiff(speakeasy_listplanmodifier.ExplicitSuppress),
								},
								ElementType: types.StringType,
								MarkdownDescription: `List of subnet IDs for compute instances.` + "\n" +
									`Subnets must be in the specified VPC. Use multiple subnets for high availability.` + "\n" +
									`Requires replacement if changed.`,
							},
							"vpc_id": schema.StringAttribute{
								Computed: true,
								Optional: true,
								PlanModifiers: []planmodifier.String{
									stringplanmodifier.RequiresReplaceIfConfigured(),
									speakeasy_stringplanmodifier.SuppressDiff(speakeasy_stringplanmodifier.ExplicitSuppress),
								},
								MarkdownDescription: `VPC ID where compute environment will be deployed.` + "\n" +
									`Format: vpc- followed by hexadecimal characters` + "\n" +
									`Requires replacement if changed.`,
								Validators: []validator.String{
									stringvalidator.RegexMatches(regexp.MustCompile(`^vpc-[a-f0-9]+$`), "must match pattern "+regexp.MustCompile(`^vpc-[a-f0-9]+$`).String()),
								},
							},
						},
						Description: `AWS Forge configuration for compute resources`,
					},
					"head_job_cpus": schema.Int32Attribute{
						Computed:    true,
						Optional:    true,
						Default:     int32default.StaticInt32(1),
						Description: `Number of CPUs allocated for the head job. Default: 1`,
					},
					"head_job_memory_mb": schema.Int32Attribute{
						Computed:    true,
						Optional:    true,
						Default:     int32default.StaticInt32(1024),
						Description: `Memory allocation for the head job in MB. Default: 1024`,
					},
					"head_job_role": schema.StringAttribute{
						Computed:    true,
						Optional:    true,
						Description: `IAM role ARN for the head job`,
						Validators: []validator.String{
							stringvalidator.RegexMatches(regexp.MustCompile(`^arn:aws:iam::[0-9]{12}:role/.+$`), "must match pattern "+regexp.MustCompile(`^arn:aws:iam::[0-9]{12}:role/.+$`).String()),
						},
					},
					"head_queue": schema.StringAttribute{
						Computed:    true,
						Optional:    true,
						Description: `Name of the head job queue`,
					},
					"post_run_script": schema.StringAttribute{
						Computed: true,
						Optional: true,
						MarkdownDescription: `Bash script to run after workflow execution completes.` + "\n" +
							`Use for cleanup, archiving results, etc.`,
					},
					"pre_run_script": schema.StringAttribute{
						Computed: true,
						Optional: true,
						MarkdownDescription: `Bash script to run before workflow execution begins.` + "\n" +
							`Use for environment setup, loading modules, etc.`,
					},
				},
			},
			"credentials_id": schema.StringAttribute{
				Required: true,
				PlanModifiers: []planmodifier.String{
					stringplanmodifier.RequiresReplaceIfConfigured(),
					speakeasy_stringplanmodifier.SuppressDiff(speakeasy_stringplanmodifier.ExplicitSuppress),
				},
				Description: `AWS credentials ID to use for accessing AWS services. Requires replacement if changed.`,
			},
			"description": schema.StringAttribute{
				Computed:    true,
				Optional:    true,
				Description: `Optional description of the compute environment`,
			},
			"label_ids": schema.ListAttribute{
				Optional: true,
				PlanModifiers: []planmodifier.List{
					listplanmodifier.RequiresReplaceIfConfigured(),
				},
				ElementType: types.Int64Type,
				Description: `Requires replacement if changed.`,
			},
			"message": schema.StringAttribute{
				Computed:    true,
				Description: `Status message or error details`,
			},
			"name": schema.StringAttribute{
				Required: true,
				PlanModifiers: []planmodifier.String{
					stringplanmodifier.RequiresReplaceIfConfigured(),
					speakeasy_stringplanmodifier.SuppressDiff(speakeasy_stringplanmodifier.ExplicitSuppress),
				},
				Description: `Display name for the compute environment (max 100 characters). Requires replacement if changed.`,
				Validators: []validator.String{
					stringvalidator.UTF8LengthAtMost(100),
				},
			},
			"region": schema.StringAttribute{
				Required: true,
				PlanModifiers: []planmodifier.String{
					stringplanmodifier.RequiresReplaceIfConfigured(),
					speakeasy_stringplanmodifier.SuppressDiff(speakeasy_stringplanmodifier.ExplicitSuppress),
				},
				MarkdownDescription: `AWS region where the Batch compute environment will be created.` + "\n" +
					`Examples: us-east-1, eu-west-1, ap-southeast-2` + "\n" +
					`Requires replacement if changed.`,
			},
			"status": schema.StringAttribute{
				Computed:    true,
				Description: `Current status of the compute environment`,
			},
			"work_directory": schema.StringAttribute{
				Required: true,
				MarkdownDescription: `S3 bucket path for Nextflow work directory where intermediate files will be stored.` + "\n" +
					`Format: s3://bucket-name/path` + "\n" +
					`Example: s3://my-nextflow-bucket/work`,
				Validators: []validator.String{
					stringvalidator.RegexMatches(regexp.MustCompile(`^s3://.+`), "must match pattern "+regexp.MustCompile(`^s3://.+`).String()),
				},
			},
			"workspace_id": schema.Int64Attribute{
				Required:    true,
				Description: `Workspace numeric identifier`,
			},
		},
	}
}

func (r *AWSBatchComputeEnvResource) Configure(ctx context.Context, req resource.ConfigureRequest, resp *resource.ConfigureResponse) {
	// Prevent panic if the provider has not been configured.
	if req.ProviderData == nil {
		return
	}

	client, ok := req.ProviderData.(*sdk.Seqera)

	if !ok {
		resp.Diagnostics.AddError(
			"Unexpected Resource Configure Type",
			fmt.Sprintf("Expected *sdk.Seqera, got: %T. Please report this issue to the provider developers.", req.ProviderData),
		)

		return
	}

	r.client = client
}

func (r *AWSBatchComputeEnvResource) Create(ctx context.Context, req resource.CreateRequest, resp *resource.CreateResponse) {
	var data *AWSBatchComputeEnvResourceModel
	var plan types.Object

	resp.Diagnostics.Append(req.Plan.Get(ctx, &plan)...)
	if resp.Diagnostics.HasError() {
		return
	}

	resp.Diagnostics.Append(plan.As(ctx, &data, basetypes.ObjectAsOptions{
		UnhandledNullAsEmpty:    true,
		UnhandledUnknownAsEmpty: true,
	})...)

	if resp.Diagnostics.HasError() {
		return
	}

	request, requestDiags := data.ToOperationsCreateAWSBatchComputeEnvRequest(ctx)
	resp.Diagnostics.Append(requestDiags...)

	if resp.Diagnostics.HasError() {
		return
	}
	res, err := r.client.ComputeEnvs.CreateAWSBatchComputeEnv(ctx, *request)
	if err != nil {
		resp.Diagnostics.AddError("failure to invoke API", err.Error())
		if res != nil && res.RawResponse != nil {
			resp.Diagnostics.AddError("unexpected http request/response", debugResponse(res.RawResponse))
		}
		return
	}
	if res == nil {
		resp.Diagnostics.AddError("unexpected response from API", fmt.Sprintf("%v", res))
		return
	}
	if res.StatusCode != 200 {
		resp.Diagnostics.AddError(fmt.Sprintf("unexpected response from API. Got an unexpected response code %v", res.StatusCode), debugResponse(res.RawResponse))
		return
	}
	if !(res.CreateAWSBatchComputeEnvResponse != nil) {
		resp.Diagnostics.AddError("unexpected response from API. Got an unexpected response body", debugResponse(res.RawResponse))
		return
	}
	resp.Diagnostics.Append(data.RefreshFromSharedCreateAWSBatchComputeEnvResponse(ctx, res.CreateAWSBatchComputeEnvResponse)...)

	if resp.Diagnostics.HasError() {
		return
	}

	resp.Diagnostics.Append(refreshPlan(ctx, plan, &data)...)

	if resp.Diagnostics.HasError() {
		return
	}
	request1, request1Diags := data.ToOperationsDescribeAWSBatchComputeEnvRequest(ctx)
	resp.Diagnostics.Append(request1Diags...)

	if resp.Diagnostics.HasError() {
		return
	}
	res1, err := r.client.ComputeEnvs.DescribeAWSBatchComputeEnv(ctx, *request1)
	if err != nil {
		resp.Diagnostics.AddError("failure to invoke API", err.Error())
		if res1 != nil && res1.RawResponse != nil {
			resp.Diagnostics.AddError("unexpected http request/response", debugResponse(res1.RawResponse))
		}
		return
	}
	if res1 == nil {
		resp.Diagnostics.AddError("unexpected response from API", fmt.Sprintf("%v", res1))
		return
	}
	if res1.StatusCode != 200 {
		resp.Diagnostics.AddError(fmt.Sprintf("unexpected response from API. Got an unexpected response code %v", res1.StatusCode), debugResponse(res1.RawResponse))
		return
	}
	if !(res1.DescribeAWSBatchComputeEnvResponse != nil) {
		resp.Diagnostics.AddError("unexpected response from API. Got an unexpected response body", debugResponse(res1.RawResponse))
		return
	}
	resp.Diagnostics.Append(data.RefreshFromSharedDescribeAWSBatchComputeEnvResponse(ctx, res1.DescribeAWSBatchComputeEnvResponse)...)

	if resp.Diagnostics.HasError() {
		return
	}

	resp.Diagnostics.Append(refreshPlan(ctx, plan, &data)...)

	if resp.Diagnostics.HasError() {
		return
	}

	// Save updated data into Terraform state
	resp.Diagnostics.Append(resp.State.Set(ctx, &data)...)
}

func (r *AWSBatchComputeEnvResource) Read(ctx context.Context, req resource.ReadRequest, resp *resource.ReadResponse) {
	var data *AWSBatchComputeEnvResourceModel
	var item types.Object

	resp.Diagnostics.Append(req.State.Get(ctx, &item)...)
	if resp.Diagnostics.HasError() {
		return
	}

	resp.Diagnostics.Append(item.As(ctx, &data, basetypes.ObjectAsOptions{
		UnhandledNullAsEmpty:    true,
		UnhandledUnknownAsEmpty: true,
	})...)

	if resp.Diagnostics.HasError() {
		return
	}

	request, requestDiags := data.ToOperationsDescribeAWSBatchComputeEnvRequest(ctx)
	resp.Diagnostics.Append(requestDiags...)

	if resp.Diagnostics.HasError() {
		return
	}
	res, err := r.client.ComputeEnvs.DescribeAWSBatchComputeEnv(ctx, *request)
	if err != nil {
		resp.Diagnostics.AddError("failure to invoke API", err.Error())
		if res != nil && res.RawResponse != nil {
			resp.Diagnostics.AddError("unexpected http request/response", debugResponse(res.RawResponse))
		}
		return
	}
	if res == nil {
		resp.Diagnostics.AddError("unexpected response from API", fmt.Sprintf("%v", res))
		return
	}
	if res.StatusCode == 404 {
		resp.State.RemoveResource(ctx)
		return
	}
	if res.StatusCode != 200 {
		resp.Diagnostics.AddError(fmt.Sprintf("unexpected response from API. Got an unexpected response code %v", res.StatusCode), debugResponse(res.RawResponse))
		return
	}
	if !(res.DescribeAWSBatchComputeEnvResponse != nil) {
		resp.Diagnostics.AddError("unexpected response from API. Got an unexpected response body", debugResponse(res.RawResponse))
		return
	}
	resp.Diagnostics.Append(data.RefreshFromSharedDescribeAWSBatchComputeEnvResponse(ctx, res.DescribeAWSBatchComputeEnvResponse)...)

	if resp.Diagnostics.HasError() {
		return
	}

	// Save updated data into Terraform state
	resp.Diagnostics.Append(resp.State.Set(ctx, &data)...)
}

func (r *AWSBatchComputeEnvResource) Update(ctx context.Context, req resource.UpdateRequest, resp *resource.UpdateResponse) {
	var data *AWSBatchComputeEnvResourceModel
	var plan types.Object

	resp.Diagnostics.Append(req.Plan.Get(ctx, &plan)...)
	if resp.Diagnostics.HasError() {
		return
	}

	merge(ctx, req, resp, &data)
	if resp.Diagnostics.HasError() {
		return
	}

	request, requestDiags := data.ToOperationsUpdateAWSBatchComputeEnvRequest(ctx)
	resp.Diagnostics.Append(requestDiags...)

	if resp.Diagnostics.HasError() {
		return
	}
	res, err := r.client.ComputeEnvs.UpdateAWSBatchComputeEnv(ctx, *request)
	if err != nil {
		resp.Diagnostics.AddError("failure to invoke API", err.Error())
		if res != nil && res.RawResponse != nil {
			resp.Diagnostics.AddError("unexpected http request/response", debugResponse(res.RawResponse))
		}
		return
	}
	if res == nil {
		resp.Diagnostics.AddError("unexpected response from API", fmt.Sprintf("%v", res))
		return
	}
	if res.StatusCode != 204 {
		resp.Diagnostics.AddError(fmt.Sprintf("unexpected response from API. Got an unexpected response code %v", res.StatusCode), debugResponse(res.RawResponse))
		return
	}

	resp.Diagnostics.Append(refreshPlan(ctx, plan, &data)...)

	if resp.Diagnostics.HasError() {
		return
	}

	// Save updated data into Terraform state
	resp.Diagnostics.Append(resp.State.Set(ctx, &data)...)
}

func (r *AWSBatchComputeEnvResource) Delete(ctx context.Context, req resource.DeleteRequest, resp *resource.DeleteResponse) {
	var data *AWSBatchComputeEnvResourceModel
	var item types.Object

	resp.Diagnostics.Append(req.State.Get(ctx, &item)...)
	if resp.Diagnostics.HasError() {
		return
	}

	resp.Diagnostics.Append(item.As(ctx, &data, basetypes.ObjectAsOptions{
		UnhandledNullAsEmpty:    true,
		UnhandledUnknownAsEmpty: true,
	})...)

	if resp.Diagnostics.HasError() {
		return
	}

	request, requestDiags := data.ToOperationsDeleteAWSBatchComputeEnvRequest(ctx)
	resp.Diagnostics.Append(requestDiags...)

	if resp.Diagnostics.HasError() {
		return
	}
	res, err := r.client.ComputeEnvs.DeleteAWSBatchComputeEnv(ctx, *request)
	if err != nil {
		resp.Diagnostics.AddError("failure to invoke API", err.Error())
		if res != nil && res.RawResponse != nil {
			resp.Diagnostics.AddError("unexpected http request/response", debugResponse(res.RawResponse))
		}
		return
	}
	if res == nil {
		resp.Diagnostics.AddError("unexpected response from API", fmt.Sprintf("%v", res))
		return
	}
	if res.StatusCode != 204 {
		resp.Diagnostics.AddError(fmt.Sprintf("unexpected response from API. Got an unexpected response code %v", res.StatusCode), debugResponse(res.RawResponse))
		return
	}

}

func (r *AWSBatchComputeEnvResource) ImportState(ctx context.Context, req resource.ImportStateRequest, resp *resource.ImportStateResponse) {
	dec := json.NewDecoder(bytes.NewReader([]byte(req.ID)))
	dec.DisallowUnknownFields()
	var data struct {
		ComputeEnvID string `json:"compute_env_id"`
		WorkspaceID  int64  `json:"workspace_id"`
	}

	if err := dec.Decode(&data); err != nil {
		resp.Diagnostics.AddError("Invalid ID", `The import ID is not valid. It is expected to be a JSON object string with the format: '{"compute_env_id": "...", "workspace_id": 0}': `+err.Error())
		return
	}

	if len(data.ComputeEnvID) == 0 {
		resp.Diagnostics.AddError("Missing required field", `The field compute_env_id is required but was not found in the json encoded ID. It's expected to be a value alike '""`)
		return
	}
	resp.Diagnostics.Append(resp.State.SetAttribute(ctx, path.Root("compute_env_id"), data.ComputeEnvID)...)
	resp.Diagnostics.Append(resp.State.SetAttribute(ctx, path.Root("workspace_id"), data.WorkspaceID)...)
}
