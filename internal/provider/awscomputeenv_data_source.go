// Code generated by Speakeasy (https://speakeasy.com). DO NOT EDIT.

package provider

import (
	"context"
	"fmt"
	"github.com/hashicorp/terraform-plugin-framework/datasource"
	"github.com/hashicorp/terraform-plugin-framework/datasource/schema"
	"github.com/hashicorp/terraform-plugin-framework/types"
	"github.com/hashicorp/terraform-plugin-framework/types/basetypes"
	tfTypes "github.com/seqeralabs/terraform-provider-seqera/internal/provider/types"
	"github.com/seqeralabs/terraform-provider-seqera/internal/sdk"
)

// Ensure provider defined types fully satisfy framework interfaces.
var _ datasource.DataSource = &AWSComputeEnvDataSource{}
var _ datasource.DataSourceWithConfigure = &AWSComputeEnvDataSource{}

func NewAWSComputeEnvDataSource() datasource.DataSource {
	return &AWSComputeEnvDataSource{}
}

// AWSComputeEnvDataSource is the data source implementation.
type AWSComputeEnvDataSource struct {
	// Provider configured SDK client.
	client *sdk.Seqera
}

// AWSComputeEnvDataSourceModel describes the data model.
type AWSComputeEnvDataSourceModel struct {
	Attributes    []types.String         `queryParam:"style=form,explode=true,name=attributes" tfsdk:"attributes"`
	ComputeEnvID  types.String           `tfsdk:"compute_env_id"`
	Config        tfTypes.AwsBatchConfig `tfsdk:"config"`
	CredentialsID types.String           `tfsdk:"credentials_id"`
	DateCreated   types.String           `tfsdk:"date_created"`
	Deleted       types.Bool             `tfsdk:"deleted"`
	Description   types.String           `tfsdk:"description"`
	LastUpdated   types.String           `tfsdk:"last_updated"`
	LastUsed      types.String           `tfsdk:"last_used"`
	Name          types.String           `tfsdk:"name"`
	OrgID         types.Int64            `tfsdk:"org_id"`
	Platform      types.String           `tfsdk:"platform"`
	Status        types.String           `tfsdk:"status"`
	WorkspaceID   types.Int64            `queryParam:"style=form,explode=true,name=workspaceId" tfsdk:"workspace_id"`
}

// Metadata returns the data source type name.
func (r *AWSComputeEnvDataSource) Metadata(ctx context.Context, req datasource.MetadataRequest, resp *datasource.MetadataResponse) {
	resp.TypeName = req.ProviderTypeName + "_aws_compute_env"
}

// Schema defines the schema for the data source.
func (r *AWSComputeEnvDataSource) Schema(ctx context.Context, req datasource.SchemaRequest, resp *datasource.SchemaResponse) {
	resp.Schema = schema.Schema{
		MarkdownDescription: "Manage AWS compute environments in Seqera platform using this resource.\n\nAWS compute environments define the execution platform where a pipeline will run\non AWS infrastructure (AWS Batch, AWS Cloud, EKS).\n",

		Attributes: map[string]schema.Attribute{
			"attributes": schema.ListAttribute{
				Optional:    true,
				ElementType: types.StringType,
				Description: `Additional attribute values to include in the response (` + "`" + `labels` + "`" + `). Returns an empty value (` + "`" + `labels: null` + "`" + `) if omitted.`,
			},
			"compute_env_id": schema.StringAttribute{
				Computed:    true,
				Description: `Compute environment string identifier`,
			},
			"config": schema.SingleNestedAttribute{
				Computed: true,
				Attributes: map[string]schema.Attribute{
					"cli_path": schema.StringAttribute{
						Computed:    true,
						Description: `Path to AWS CLI on compute instances. AWS CLI must be available at this path.`,
					},
					"compute_job_role": schema.StringAttribute{
						Computed: true,
						MarkdownDescription: `IAM role ARN for compute jobs. Jobs assume this role during execution.` + "\n" +
							`Must have permissions for S3, CloudWatch, etc.` + "\n" +
							`Format: arn:aws:iam::account-id:role/role-name`,
					},
					"compute_queue": schema.StringAttribute{
						Computed:    true,
						Description: `Name of the AWS Batch compute queue`,
					},
					"dragen_instance_type": schema.StringAttribute{
						Computed: true,
					},
					"dragen_queue": schema.StringAttribute{
						Computed: true,
					},
					"enable_fusion": schema.BoolAttribute{
						Computed: true,
					},
					"enable_wave": schema.BoolAttribute{
						Computed: true,
						MarkdownDescription: `Enable Wave containers for this compute environment. Wave provides container provisioning` + "\n" +
							`and augmentation capabilities for Nextflow workflows.` + "\n" +
							`` + "\n" +
							`When enable_wave is true, enable_fusion must be explicitly set to either true or false.` + "\n" +
							`Note: If Fusion2 is enabled, Wave must also be enabled.`,
					},
					"environment": schema.ListNestedAttribute{
						Computed: true,
						NestedObject: schema.NestedAttributeObject{
							Attributes: map[string]schema.Attribute{
								"compute": schema.BoolAttribute{
									Computed: true,
								},
								"head": schema.BoolAttribute{
									Computed: true,
								},
								"name": schema.StringAttribute{
									Computed: true,
								},
								"value": schema.StringAttribute{
									Computed: true,
								},
							},
						},
					},
					"execution_role": schema.StringAttribute{
						Computed: true,
						MarkdownDescription: `IAM role ARN for Batch execution (pulling container images, writing logs).` + "\n" +
							`Must have permissions for ECR and CloudWatch Logs.` + "\n" +
							`Format: arn:aws:iam::account-id:role/role-name`,
					},
					"forge": schema.SingleNestedAttribute{
						Computed: true,
						Attributes: map[string]schema.Attribute{
							"alloc_strategy": schema.StringAttribute{
								Computed: true,
								MarkdownDescription: `Strategy for allocating compute resources:` + "\n" +
									`- BEST_FIT: Selects instance type that best fits job requirements` + "\n" +
									`- BEST_FIT_PROGRESSIVE: Similar to BEST_FIT but widens search progressively` + "\n" +
									`- SPOT_CAPACITY_OPTIMIZED: For Spot instances, selects from pools with optimal capacity` + "\n" +
									`- SPOT_PRICE_CAPACITY_OPTIMIZED: Optimizes for both price and capacity` + "\n" +
									`Note: SPOT_CAPACITY_OPTIMIZED only valid when type is SPOT`,
							},
							"allow_buckets": schema.ListAttribute{
								Computed:    true,
								ElementType: types.StringType,
							},
							"arm64_enabled": schema.BoolAttribute{
								Computed: true,
							},
							"bid_percentage": schema.Int32Attribute{
								Computed: true,
								MarkdownDescription: `The maximum percentage that a Spot Instance price can be when compared with the On-Demand price` + "\n" +
									`for that instance type before instances are launched. For example, if your maximum percentage is 20%,` + "\n" +
									`then the Spot price must be less than 20% of the current On-Demand price for that Amazon EC2 instance.` + "\n" +
									`You always pay the lowest (market) price and never more than your maximum percentage. If you leave this` + "\n" +
									`field empty, the default value is 100% of the On-Demand price. For most use cases, we recommend leaving` + "\n" +
									`this field empty.` + "\n" +
									`` + "\n" +
									`Must be a whole number between 0 and 100 (inclusive).`,
							},
							"dispose_on_deletion": schema.BoolAttribute{
								Computed:    true,
								Description: `Dispose of AWS Batch resources when compute environment is deleted.`,
							},
							"dragen_ami_id": schema.StringAttribute{
								Computed: true,
							},
							"dragen_enabled": schema.BoolAttribute{
								Computed: true,
							},
							"dragen_instance_type": schema.StringAttribute{
								Computed: true,
							},
							"ebs_auto_scale": schema.BoolAttribute{
								Computed: true,
								MarkdownDescription: `Enable automatic EBS volume expansion.` + "\n" +
									`When enabled, EBS volumes automatically expand as needed.`,
							},
							"ebs_block_size": schema.Int32Attribute{
								Computed:    true,
								Description: `Size of EBS root volume in GB (minimum 8 GB, maximum 16 TB).`,
							},
							"ebs_boot_size": schema.Int32Attribute{
								Computed: true,
							},
							"ec2_key_pair": schema.StringAttribute{
								Computed: true,
								MarkdownDescription: `EC2 key pair name for SSH access to compute instances.` + "\n" +
									`Key pair must exist in the specified region.`,
							},
							"ecs_config": schema.StringAttribute{
								Computed: true,
							},
							"efs_create": schema.BoolAttribute{
								Computed:    true,
								Description: `Automatically create an EFS file system`,
							},
							"efs_id": schema.StringAttribute{
								Computed: true,
								MarkdownDescription: `EFS file system ID to mount.` + "\n" +
									`Format: fs- followed by hexadecimal characters.` + "\n" +
									`EFS must be in the same VPC and region.`,
							},
							"efs_mount": schema.StringAttribute{
								Computed:    true,
								Description: `Path where EFS will be mounted in the container.`,
							},
							"fargate_head_enabled": schema.BoolAttribute{
								Computed: true,
								MarkdownDescription: `Use Fargate for head job instead of EC2.` + "\n" +
									`Reduces costs by running head job on serverless compute.` + "\n" +
									`Only applicable when using EC2 for worker jobs.`,
							},
							"fsx_mount": schema.StringAttribute{
								Computed:    true,
								Description: `Path where FSx will be mounted in the container.`,
							},
							"fsx_name": schema.StringAttribute{
								Computed:    true,
								Description: `FSx for Lustre file system name.`,
							},
							"fsx_size": schema.Int32Attribute{
								Computed:    true,
								Description: `Size of FSx file system in GB.`,
							},
							"gpu_enabled": schema.BoolAttribute{
								Computed: true,
								MarkdownDescription: `Enable GPU support for compute instances.` + "\n" +
									`When enabled, GPU-capable instance types will be selected.`,
							},
							"image_id": schema.StringAttribute{
								Computed: true,
							},
							"instance_types": schema.ListAttribute{
								Computed:    true,
								ElementType: types.StringType,
								MarkdownDescription: `List of EC2 instance types to use.` + "\n" +
									`Examples: ["m5.xlarge", "m5.2xlarge"], ["c5.2xlarge"], ["p3.2xlarge"]` + "\n" +
									`Default: ["optimal"] - AWS Batch selects appropriate instances`,
							},
							"max_cpus": schema.Int32Attribute{
								Computed: true,
								MarkdownDescription: `Maximum number of CPUs available in the compute environment.` + "\n" +
									`Subject to AWS service quotas.`,
							},
							"min_cpus": schema.Int32Attribute{
								Computed: true,
								MarkdownDescription: `Minimum number of CPUs to maintain in the compute environment.` + "\n" +
									`Setting to 0 allows environment to scale to zero when idle.`,
							},
							"security_groups": schema.ListAttribute{
								Computed:    true,
								ElementType: types.StringType,
								MarkdownDescription: `List of security group IDs to attach to compute instances.` + "\n" +
									`Security groups must allow necessary network access.`,
							},
							"subnets": schema.ListAttribute{
								Computed:    true,
								ElementType: types.StringType,
								MarkdownDescription: `List of subnet IDs for compute instances.` + "\n" +
									`Subnets must be in the specified VPC. Use multiple subnets for high availability.` + "\n" +
									`Must have sufficient IP addresses.`,
							},
							"type": schema.StringAttribute{
								Computed: true,
								MarkdownDescription: `Type of compute instances to provision:` + "\n" +
									`- SPOT: Use EC2 Spot instances (cost-effective, can be interrupted)` + "\n" +
									`- EC2: Use On-Demand EC2 instances (reliable, higher cost)` + "\n" +
									`- FARGATE: Use AWS Fargate serverless compute`,
							},
							"vpc_id": schema.StringAttribute{
								Computed: true,
								MarkdownDescription: `VPC ID where compute environment will be deployed.` + "\n" +
									`Format: vpc- followed by hexadecimal characters`,
							},
						},
					},
					"fusion_snapshots": schema.BoolAttribute{
						Computed: true,
					},
					"head_job_cpus": schema.Int32Attribute{
						Computed:    true,
						Description: `Number of CPUs allocated for the head job (default: 1)`,
					},
					"head_job_memory_mb": schema.Int32Attribute{
						Computed:    true,
						Description: `Memory allocation for the head job in MB (default: 1024)`,
					},
					"head_job_role": schema.StringAttribute{
						Computed: true,
						MarkdownDescription: `IAM role ARN for the head job.` + "\n" +
							`Format: arn:aws:iam::account-id:role/role-name`,
					},
					"head_queue": schema.StringAttribute{
						Computed:    true,
						Description: `Name of the head job queue`,
					},
					"log_group": schema.StringAttribute{
						Computed: true,
					},
					"lustre_id": schema.StringAttribute{
						Computed:           true,
						DeprecationMessage: `This will be removed in a future release, please migrate away from it as soon as possible`,
					},
					"nextflow_config": schema.StringAttribute{
						Computed: true,
					},
					"nvme_storage_enabled": schema.BoolAttribute{
						Computed: true,
						MarkdownDescription: `Enable NVMe instance storage for high-performance I/O.` + "\n" +
							`When enabled, NVMe storage volumes are automatically mounted and configured.`,
					},
					"post_run_script": schema.StringAttribute{
						Computed: true,
						MarkdownDescription: `Bash script to run after workflow execution completes.` + "\n" +
							`Use for cleanup, archiving results, sending notifications, etc.`,
					},
					"pre_run_script": schema.StringAttribute{
						Computed: true,
						MarkdownDescription: `Bash script to run before workflow execution begins.` + "\n" +
							`Use for environment setup, loading modules, downloading reference data, etc.`,
					},
					"region": schema.StringAttribute{
						Computed: true,
						MarkdownDescription: `AWS region where the Batch compute environment will be created.` + "\n" +
							`Examples: us-east-1, eu-west-1, ap-southeast-2`,
					},
					"storage_type": schema.StringAttribute{
						Computed:           true,
						DeprecationMessage: `This will be removed in a future release, please migrate away from it as soon as possible`,
					},
					"volumes": schema.ListAttribute{
						Computed:    true,
						ElementType: types.StringType,
					},
					"work_dir": schema.StringAttribute{
						Computed: true,
						MarkdownDescription: `S3 bucket path for Nextflow work directory where intermediate files will be stored.` + "\n" +
							`Format: s3://bucket-name/path`,
					},
				},
			},
			"credentials_id": schema.StringAttribute{
				Computed:    true,
				Description: `AWS credentials identifier`,
			},
			"date_created": schema.StringAttribute{
				Computed:    true,
				Description: `Timestamp when the compute environment was created`,
			},
			"deleted": schema.BoolAttribute{
				Computed:    true,
				Description: `Flag indicating if the compute environment has been deleted`,
			},
			"description": schema.StringAttribute{
				Computed:    true,
				Description: `Optional description of the compute environment`,
			},
			"last_updated": schema.StringAttribute{
				Computed:    true,
				Description: `Timestamp when the compute environment was last updated`,
			},
			"last_used": schema.StringAttribute{
				Computed:    true,
				Description: `Timestamp when the compute environment was last used`,
			},
			"name": schema.StringAttribute{
				Computed:    true,
				Description: `Display name for the compute environment`,
			},
			"org_id": schema.Int64Attribute{
				Computed: true,
			},
			"platform": schema.StringAttribute{
				Computed:    true,
				Description: `AWS platform type`,
			},
			"status": schema.StringAttribute{
				Computed:    true,
				Description: `Compute environment status`,
			},
			"workspace_id": schema.Int64Attribute{
				Required:    true,
				Description: `Workspace numeric identifier`,
			},
		},
	}
}

func (r *AWSComputeEnvDataSource) Configure(ctx context.Context, req datasource.ConfigureRequest, resp *datasource.ConfigureResponse) {
	// Prevent panic if the provider has not been configured.
	if req.ProviderData == nil {
		return
	}

	client, ok := req.ProviderData.(*sdk.Seqera)

	if !ok {
		resp.Diagnostics.AddError(
			"Unexpected DataSource Configure Type",
			fmt.Sprintf("Expected *sdk.Seqera, got: %T. Please report this issue to the provider developers.", req.ProviderData),
		)

		return
	}

	r.client = client
}

func (r *AWSComputeEnvDataSource) Read(ctx context.Context, req datasource.ReadRequest, resp *datasource.ReadResponse) {
	var data *AWSComputeEnvDataSourceModel
	var item types.Object

	resp.Diagnostics.Append(req.Config.Get(ctx, &item)...)
	if resp.Diagnostics.HasError() {
		return
	}

	resp.Diagnostics.Append(item.As(ctx, &data, basetypes.ObjectAsOptions{
		UnhandledNullAsEmpty:    true,
		UnhandledUnknownAsEmpty: true,
	})...)

	if resp.Diagnostics.HasError() {
		return
	}

	request, requestDiags := data.ToOperationsDescribeAWSComputeEnvRequest(ctx)
	resp.Diagnostics.Append(requestDiags...)

	if resp.Diagnostics.HasError() {
		return
	}
	res, err := r.client.ComputeEnvs.DescribeAWSComputeEnv(ctx, *request)
	if err != nil {
		resp.Diagnostics.AddError("failure to invoke API", err.Error())
		if res != nil && res.RawResponse != nil {
			resp.Diagnostics.AddError("unexpected http request/response", debugResponse(res.RawResponse))
		}
		return
	}
	if res == nil {
		resp.Diagnostics.AddError("unexpected response from API", fmt.Sprintf("%v", res))
		return
	}
	if res.StatusCode != 200 {
		resp.Diagnostics.AddError(fmt.Sprintf("unexpected response from API. Got an unexpected response code %v", res.StatusCode), debugResponse(res.RawResponse))
		return
	}
	if !(res.DescribeAWSComputeEnvResponse != nil) {
		resp.Diagnostics.AddError("unexpected response from API. Got an unexpected response body", debugResponse(res.RawResponse))
		return
	}
	resp.Diagnostics.Append(data.RefreshFromSharedDescribeAWSComputeEnvResponse(ctx, res.DescribeAWSComputeEnvResponse)...)

	if resp.Diagnostics.HasError() {
		return
	}

	// Save updated data into Terraform state
	resp.Diagnostics.Append(resp.State.Set(ctx, &data)...)
}
