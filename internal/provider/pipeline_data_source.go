// Code generated by Speakeasy (https://speakeasy.com). DO NOT EDIT.

package provider

import (
	"context"
	"fmt"
	"github.com/hashicorp/terraform-plugin-framework/datasource"
	"github.com/hashicorp/terraform-plugin-framework/datasource/schema"
	"github.com/hashicorp/terraform-plugin-framework/types"
	"github.com/hashicorp/terraform-plugin-framework/types/basetypes"
	tfTypes "github.com/speakeasy/terraform-provider-seqera/internal/provider/types"
	"github.com/speakeasy/terraform-provider-seqera/internal/sdk"
)

// Ensure provider defined types fully satisfy framework interfaces.
var _ datasource.DataSource = &PipelineDataSource{}
var _ datasource.DataSourceWithConfigure = &PipelineDataSource{}

func NewPipelineDataSource() datasource.DataSource {
	return &PipelineDataSource{}
}

// PipelineDataSource is the data source implementation.
type PipelineDataSource struct {
	// Provider configured SDK client.
	client *sdk.Seqera
}

// PipelineDataSourceModel describes the data model.
type PipelineDataSourceModel struct {
	Attributes          []types.String           `queryParam:"style=form,explode=false,name=attributes" tfsdk:"attributes"`
	ComputeEnv          *tfTypes.ComputeEnvDbDto `tfsdk:"compute_env"`
	Deleted             types.Bool               `tfsdk:"deleted"`
	Description         types.String             `tfsdk:"description"`
	Icon                types.String             `tfsdk:"icon"`
	Labels              []tfTypes.LabelDbDto     `tfsdk:"labels"`
	LastUpdated         types.String             `tfsdk:"last_updated"`
	Name                types.String             `tfsdk:"name"`
	OptimizationID      types.String             `tfsdk:"optimization_id"`
	OptimizationStatus  types.String             `tfsdk:"optimization_status"`
	OptimizationTargets types.String             `tfsdk:"optimization_targets"`
	OrgID               types.Int64              `tfsdk:"org_id"`
	OrgName             types.String             `tfsdk:"org_name"`
	PipelineID          types.Int64              `tfsdk:"pipeline_id"`
	Repository          types.String             `tfsdk:"repository"`
	SourceWorkspaceID   types.Int64              `queryParam:"style=form,explode=true,name=sourceWorkspaceId" tfsdk:"source_workspace_id"`
	UserFirstName       types.String             `tfsdk:"user_first_name"`
	UserID              types.Int64              `tfsdk:"user_id"`
	UserLastName        types.String             `tfsdk:"user_last_name"`
	UserName            types.String             `tfsdk:"user_name"`
	Visibility          types.String             `tfsdk:"visibility"`
	WorkspaceID         types.Int64              `queryParam:"style=form,explode=true,name=workspaceId" tfsdk:"workspace_id"`
	WorkspaceName       types.String             `tfsdk:"workspace_name"`
}

// Metadata returns the data source type name.
func (r *PipelineDataSource) Metadata(ctx context.Context, req datasource.MetadataRequest, resp *datasource.MetadataResponse) {
	resp.TypeName = req.ProviderTypeName + "_pipeline"
}

// Schema defines the schema for the data source.
func (r *PipelineDataSource) Schema(ctx context.Context, req datasource.SchemaRequest, resp *datasource.SchemaResponse) {
	resp.Schema = schema.Schema{
		MarkdownDescription: "Pipeline DataSource",

		Attributes: map[string]schema.Attribute{
			"attributes": schema.ListAttribute{
				Optional:    true,
				ElementType: types.StringType,
				Description: `Additional attribute values to include in the response (` + "`" + `labels` + "`" + `, ` + "`" + `optimized` + "`" + ` status, ` + "`" + `computeEnv` + "`" + `). Returns an empty value (` + "`" + `labels: null` + "`" + `, etc.) if omitted.`,
			},
			"compute_env": schema.SingleNestedAttribute{
				Computed: true,
				Attributes: map[string]schema.Attribute{
					"id": schema.StringAttribute{
						Computed: true,
					},
					"name": schema.StringAttribute{
						Computed: true,
					},
					"platform": schema.StringAttribute{
						Computed: true,
					},
					"region": schema.StringAttribute{
						Computed: true,
					},
				},
			},
			"deleted": schema.BoolAttribute{
				Computed: true,
			},
			"description": schema.StringAttribute{
				Computed: true,
			},
			"icon": schema.StringAttribute{
				Computed: true,
			},
			"labels": schema.ListNestedAttribute{
				Computed: true,
				NestedObject: schema.NestedAttributeObject{
					Attributes: map[string]schema.Attribute{
						"date_created": schema.StringAttribute{
							Computed: true,
						},
						"id": schema.Int64Attribute{
							Computed: true,
						},
						"is_default": schema.BoolAttribute{
							Computed: true,
						},
						"name": schema.StringAttribute{
							Computed: true,
						},
						"resource": schema.BoolAttribute{
							Computed: true,
						},
						"value": schema.StringAttribute{
							Computed: true,
						},
					},
				},
			},
			"last_updated": schema.StringAttribute{
				Computed: true,
			},
			"name": schema.StringAttribute{
				Computed: true,
			},
			"optimization_id": schema.StringAttribute{
				Computed: true,
			},
			"optimization_status": schema.StringAttribute{
				Computed: true,
			},
			"optimization_targets": schema.StringAttribute{
				Computed: true,
			},
			"org_id": schema.Int64Attribute{
				Computed: true,
			},
			"org_name": schema.StringAttribute{
				Computed: true,
			},
			"pipeline_id": schema.Int64Attribute{
				Required:    true,
				Description: `Pipeline numeric identifier`,
			},
			"repository": schema.StringAttribute{
				Computed: true,
			},
			"source_workspace_id": schema.Int64Attribute{
				Optional:    true,
				Description: `Source Optional workspace numeric identifier`,
			},
			"user_first_name": schema.StringAttribute{
				Computed: true,
			},
			"user_id": schema.Int64Attribute{
				Computed: true,
			},
			"user_last_name": schema.StringAttribute{
				Computed: true,
			},
			"user_name": schema.StringAttribute{
				Computed: true,
			},
			"visibility": schema.StringAttribute{
				Computed: true,
			},
			"workspace_id": schema.Int64Attribute{
				Computed:    true,
				Optional:    true,
				Description: `Workspace numeric identifier`,
			},
			"workspace_name": schema.StringAttribute{
				Computed: true,
			},
		},
	}
}

func (r *PipelineDataSource) Configure(ctx context.Context, req datasource.ConfigureRequest, resp *datasource.ConfigureResponse) {
	// Prevent panic if the provider has not been configured.
	if req.ProviderData == nil {
		return
	}

	client, ok := req.ProviderData.(*sdk.Seqera)

	if !ok {
		resp.Diagnostics.AddError(
			"Unexpected DataSource Configure Type",
			fmt.Sprintf("Expected *sdk.Seqera, got: %T. Please report this issue to the provider developers.", req.ProviderData),
		)

		return
	}

	r.client = client
}

func (r *PipelineDataSource) Read(ctx context.Context, req datasource.ReadRequest, resp *datasource.ReadResponse) {
	var data *PipelineDataSourceModel
	var item types.Object

	resp.Diagnostics.Append(req.Config.Get(ctx, &item)...)
	if resp.Diagnostics.HasError() {
		return
	}

	resp.Diagnostics.Append(item.As(ctx, &data, basetypes.ObjectAsOptions{
		UnhandledNullAsEmpty:    true,
		UnhandledUnknownAsEmpty: true,
	})...)

	if resp.Diagnostics.HasError() {
		return
	}

	request, requestDiags := data.ToOperationsDescribePipelineRequest(ctx)
	resp.Diagnostics.Append(requestDiags...)

	if resp.Diagnostics.HasError() {
		return
	}
	res, err := r.client.Pipelines.DescribePipeline(ctx, *request)
	if err != nil {
		resp.Diagnostics.AddError("failure to invoke API", err.Error())
		if res != nil && res.RawResponse != nil {
			resp.Diagnostics.AddError("unexpected http request/response", debugResponse(res.RawResponse))
		}
		return
	}
	if res == nil {
		resp.Diagnostics.AddError("unexpected response from API", fmt.Sprintf("%v", res))
		return
	}
	if res.StatusCode != 200 {
		resp.Diagnostics.AddError(fmt.Sprintf("unexpected response from API. Got an unexpected response code %v", res.StatusCode), debugResponse(res.RawResponse))
		return
	}
	if !(res.DescribePipelineResponse != nil && res.DescribePipelineResponse.Pipeline != nil) {
		resp.Diagnostics.AddError("unexpected response from API. Got an unexpected response body", debugResponse(res.RawResponse))
		return
	}
	resp.Diagnostics.Append(data.RefreshFromSharedPipelineDbDto(ctx, res.DescribePipelineResponse.Pipeline)...)

	if resp.Diagnostics.HasError() {
		return
	}

	// Save updated data into Terraform state
	resp.Diagnostics.Append(resp.State.Set(ctx, &data)...)
}
