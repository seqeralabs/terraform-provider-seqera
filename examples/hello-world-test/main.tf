## Organizations
resource "seqera_orgs" "test_org" {
  description = "testing org for the terraform provider"
  full_name   = "seqera_test_shahbaz_tf_provider"
  name        = "seqera_test_shahbaz_tf_provider"
}

## Workspaces
resource  "seqera_workspace" "my_workspace" {
  description = "A test workspace created with Terraform"
  name        = "test-workspace-tf"
  full_name   = "Test Workspace for Terraform Provider"
  org_id     = resource.seqera_orgs.test_org.org_id
  visibility = "PRIVATE"
}

## Datasets
resource "seqera_datasets" "my_datasets" {
  description  = "Terraform created dataset"
  name         = "terraform-dataset"
  workspace_id = resource.seqera_workspace.my_workspace.id
}


## Credentials
resource "seqera_credential" "aws_credential" {

  name          = "test_credential"
  provider_type = "aws"
  workspace_id  = resource.seqera_workspace.my_workspace.id
  description   = "AWS credentials generated by terraform"    
  keys = {
    aws = {
      access_key      = var.access_key
      secret_key      = var.secret_key
      assume_role_arn = "arn:aws:iam::128997144437:role/TowerDevelopmentRole"  
      discriminator = "aws"
    }
      
  }
  
}


## Compute Environments
resource "seqera_compute_env" "aws_batch_compute_env" {
  workspace_id = resource.seqera_workspace.my_workspace.id
  
  compute_env = {
    name         = "aws-batch-compute-env"
    description  = "AWS Batch compute environment for bioinformatics workflows"
    platform     = "aws-batch"
    credentials_id = resource.seqera_credential.aws_credential.credentials_id
    
    config = {
      aws_batch = {
        discriminator    = "aws-batch"
        region          = "us-east-1" 
        work_dir        = local.work_dir 
        
        
        # Head job configuration
        head_job_cpus      = 2
        head_job_memory_mb = 4096
        
        # Features
        fusion2_enabled = true
        wave_enabled    = true
        

        # Optional: Forge configuration for auto-scaling
        forge = {
          dispose_on_deletion = true
          type               = "EC2" # or "SPOT" for cost savings
          alloc_strategy     = "BEST_FIT_PROGRESSIVE"
          
          # Instance configuration
          instance_types = ["m5.large", "m5.xlarge", "m5.2xlarge"]
          min_cpus      = 0
          max_cpus      = 1000
          

          ebs_auto_scale  = false
          gpu_enabled = false
          arm64_enabled = false
          
        #   # Optional: EC2 key pair for debugging
        #   ec2_key_pair = var.ec2_key_pair_name
        }
        
        # Optional: Custom Nextflow configuration
        nextflow_config = <<-EOF
          process {
            executor = 'awsbatch'
            queue = 'default'
          }
          aws {
            region = 'us-east-1'}'
            batch {
              cliPath = '/home/ec2-user/miniconda/bin/aws'
            }
          }
        EOF
        
        # Optional: Pre and post-run scripts
        pre_run_script = <<-EOF
          #!/bin/bash
          echo "Starting workflow execution..."
          # Add any setup commands here
        EOF
        
        post_run_script = <<-EOF
          #!/bin/bash
          echo "Workflow execution completed!"
          # Add any cleanup commands here
        EOF
      }
    }
  }
}

## Data Link
resource "seqera_data_link" "my_datalink" {
  credentials_id    = resource.seqera_credential.aws_credential.credentials_id
  description       = "data link created by Terraform"
  name              = "terraform-datalink"
  provider_type     = "aws"
  public_accessible = false
  type              = "bucket"
  workspace_id      = resource.seqera_workspace.my_workspace.id
  resource_ref     = local.work_dir
}

## Actions 
resource "seqera_action" "my_action" {
  launch = {
    compute_env_id = resource.seqera_compute_env.aws_batch_compute_env.compute_env_id
    config_profiles = [ ]
    config_text        = ""
    pipeline             = "https://github.com/nextflow-io/hello"
    pre_run_script = <<-EOF
      #!/bin/bash
      echo "Starting workflow execution..."
      # Add any setup commands here
    EOF
    
    post_run_script = <<-EOF
      #!/bin/bash
      echo "Workflow execution completed!"
      # Add any cleanup commands here
    EOF
      
    pull_latest          = true
    resume               = true
    revision             = "master"
    #run_name             = "...my_run_name..." this should be auto generated
    work_dir = local.work_dir
  }
  name         = "terraform-hello-world-action"
  workspace_id = resource.seqera_workspace.my_workspace.id
  source = "tower" 
}

## Pipelines

resource "seqera_pipeline" "hello_world_minimal" {
  description = "Hello world pipeline generated by terraform"
  name                 = "terraform-hello-world"
  launch = {
    compute_env_id = resource.seqera_compute_env.aws_batch_compute_env.compute_env_id
    config_profiles = []
    head_job_cpus      = 6
    # head_job_memory_mb = 32
    pipeline             = "https://github.com/nextflow-io/hello"
    pull_latest          = true
    resume               = false
    revision             = "master"
    work_dir = local.work_dir
  }
  workspace_id = resource.seqera_workspace.my_workspace.id
}

## Pipeline Secrets
resource "seqera_pipeline_secret" "my_pipelinesecret" {
  name         = "test_terraform_secret"
  value        = "SECRET_VALUE"
  workspace_id = resource.seqera_workspace.my_workspace.id
}

## Teams
resource "seqera_teams" "my_teams" {
  description = "Team created by Terraform"
  name        = "terraform-test-team"
  org_id      = resource.seqera_orgs.test_org.org_id
}


