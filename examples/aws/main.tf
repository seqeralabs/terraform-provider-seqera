## Organizations
resource "seqera_orgs" "my_org" {
  description = "Example org for running AWS centric workflows"
  full_name   = "aws-example-org"
  name        = "aws-example-org"
}

## Workspaces
resource "seqera_workspace" "my_workspace" {
  description = "An example aws workspace created with Terraform"
  name        = "example-workspace-aws"
  full_name   = "Example Workspace "
  org_id      = resource.seqera_orgs.my_org.org_id
  visibility  = "PRIVATE"
}

## Datasets
resource "seqera_datasets" "my_datasets" {
  description  = "Example dataset"
  name         = "terraform-dataset"
  workspace_id = resource.seqera_workspace.my_workspace.id
}


## Pipeline Secrets
resource "seqera_pipeline_secret" "my_pipelinesecret" {
  name         = "example_terraform_secret"
  value        = "SECRET_VALUE"
  workspace_id = resource.seqera_workspace.my_workspace.id
}

## Teams
resource "seqera_teams" "my_teams" {
  description = "Team created by Terraform"
  name        = "terraform-example-team"
  org_id      = resource.seqera_orgs.my_org.org_id
}




# AWS Credential
resource "seqera_credential" "aws_credential" {
  name          = "aws-terraform-credential"
  provider_type = "aws"
  workspace_id  = resource.seqera_workspace.my_workspace.id
  description   = "AWS credentials generated by Terraform"
  keys = {
    aws = {
      access_key      = var.access_key
      secret_key      = var.secret_key
      assume_role_arn = var.iam_role
    }
  }
}

# AWS Batch Compute Environment
resource "seqera_compute_env" "aws_batch_compute_env" {
  workspace_id = resource.seqera_workspace.my_workspace.id

  compute_env = {
    name           = "aws-batch-compute-env"
    description    = "AWS Batch compute environment for bioinformatics workflows"
    platform       = "aws-batch"
    credentials_id = resource.seqera_credential.aws_credential.credentials_id

    config = {
      aws_batch = {
        discriminator = "aws-batch"
        region        = var.aws_region
        work_dir      = var.work_dir

        # Head job configuration
        head_job_cpus      = 2
        head_job_memory_mb = 4096

        # Features
        fusion2_enabled = true
        wave_enabled    = true

        # Forge configuration for auto-scaling
        forge = {
          dispose_on_deletion = true
          type                = "EC2" # or "SPOT" for cost savings
          alloc_strategy      = "BEST_FIT_PROGRESSIVE"

          # Instance configuration
          instance_types = ["m5.large", "m5.xlarge", "m5.2xlarge"]
          min_cpus       = 0
          max_cpus       = 1000


          ebs_auto_scale = false
          gpu_enabled    = false
          arm64_enabled  = false

        }

        # Pre and post-run scripts
        pre_run_script = <<-EOF
          #!/bin/bash
          echo "Starting workflow execution..."
          # Add any setup commands here
        EOF

        post_run_script = <<-EOF
          #!/bin/bash
          echo "Workflow execution completed!"
          # Add any cleanup commands here
        EOF
      }
    }
  }
}

# S3 Data Link
resource "seqera_data_link" "my_datalink" {
  credentials_id    = resource.seqera_credential.aws_credential.credentials_id
  description       = "data link created by Terraform"
  name              = "terraform-datalink-s3"
  provider_type     = "aws"
  public_accessible = false
  type              = "bucket"
  workspace_id      = resource.seqera_workspace.my_workspace.id
  resource_ref      = var.work_dir
}

# Workflow Action
resource "seqera_action" "my_action" {
  launch = {
    compute_env_id  = resource.seqera_compute_env.aws_batch_compute_env.compute_env_id
    config_profiles = []
    config_text     = ""
    pipeline        = "https://github.com/nf-core/sarek"
    pre_run_script  = <<-EOF
      #!/bin/bash
      echo "Starting workflow execution..."
      # Add any setup commands here
    EOF

    post_run_script = <<-EOF
      #!/bin/bash
      echo "Workflow execution completed!"
      # Add any cleanup commands here
    EOF

    pull_latest = true
    resume      = true
    revision    = "master"
    work_dir = var.work_dir
  }
  name         = "terraform-hello-world-action"
  workspace_id = resource.seqera_workspace.my_workspace.id
  source       = "tower"
}

# Pipeline Definition
resource "seqera_pipeline" "hello_world_minimal" {
  description = "Hello world pipeline generated by terraform"
  name        = "terraform-hello-world"
  launch = {
    compute_env_id  = resource.seqera_compute_env.aws_batch_compute_env.compute_env_id
    config_profiles = []
    head_job_cpus   = 6
    pipeline    = "https://github.com/nextflow-io/hello"
    pull_latest = true
    resume      = false
    revision    = "master"
    work_dir    = var.work_dir
  }
  workspace_id = resource.seqera_workspace.my_workspace.id
}



# Workflow Launch
resource "seqera_workflows" "my_workflows" {
  compute_env_id = resource.seqera_compute_env.aws_batch_compute_env.compute_env_id
  pipeline       = "nextflow-io/hello"
  work_dir       = var.work_dir
  workspace_id   = resource.seqera_workspace.my_workspace.id
  depends_on     = [seqera_compute_env.aws_batch_compute_env]

}


# Data Studio
resource "seqera_studios" "my_datastudios" {
  compute_env_id = resource.seqera_compute_env.aws_batch_compute_env.compute_env_id
  description    = "Data studio"
  name           = "Terraform-Data-Studio"
  configuration = {}
  workspace_id         = resource.seqera_workspace.my_workspace.id
  data_studio_tool_url = "public.cr.seqera.io/platform/data-studio-jupyter:4.2.5-0.8"
  depends_on           = [seqera_compute_env.aws_batch_compute_env]
}


resource "seqera_labels" "my_labels" {
  is_default   = false
  name         = "terraform-example-label"
  resource     = true
  value        = "terraform-label-value"
  workspace_id = resource.seqera_workspace.my_workspace.id
}
